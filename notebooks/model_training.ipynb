{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05050d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils);\n",
    "from utils import *\n",
    "from termcolor import colored\n",
    "from tensorflow.keras import layers, Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6031aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path  = '../data/list_eval_partition.csv'\n",
    "image_dir = '../data/img_align_celeba/img_align_celeba/'\n",
    "\n",
    "# Load partition info\n",
    "df = load_partition_csv(csv_path)\n",
    "\n",
    "# Build train/val/test file lists\n",
    "train_files, val_files, test_files = build_file_lists(df, image_dir)\n",
    "\n",
    "# Create datasets\n",
    "train_ds = make_image_dataset(train_files, img_size=(64,64), batch_size=64, shuffle=True).take(20)\n",
    "val_ds   = make_image_dataset(val_files,   img_size=(64, 64), batch_size=64)\n",
    "test_ds  = make_image_dataset(test_files,  img_size=(64, 64), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d625b3c",
   "metadata": {},
   "source": [
    "\n",
    "## Definicja modelu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81f13e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        #batch = tf.shape(z_mean)[0]\n",
    "        #dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(64, 100))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b78922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mEncoder:\u001b[0m\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "\u001b[34mTest prediction shape of 1 batch:\u001b[0m (64, 100)\n",
      "\u001b[31mDecoder:\u001b[0m\n",
      "2/2 [==============================] - 0s 27ms/step\n",
      "\u001b[34mTest prediction shape of 1 batch:\u001b[0m (64, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1) Definicja wejścia enkodera\n",
    "latent_dim = 100  # wymiar przestrzeni latentnej\n",
    "print(colored(\"Encoder:\",\"red\"))\n",
    "\n",
    "encoder_inputs = Input(shape=(64, 64, 3), name=\"encoder_input\")  \n",
    "# (218×178 RGB) :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "# 2) Warstwy konwolucyjne\n",
    "# zamiast MaxPooling używamy Conv2D z strides=2\n",
    "x = layers.Conv2D(32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Flatten()(x)  \n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x) \n",
    "# 3) średnia, log-wariancja i próbkowanie\n",
    "z_mean    = layers.Dense(latent_dim, name=\"z_mean\")(x)      \n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "# 4) Model enkodera z dwoma wyjściami\n",
    "encoder = Model(encoder_inputs, [z_mean,z_log_var,z], name=\"encoder\")\n",
    "z_predict = encoder.predict(train_ds.take(1))\n",
    "print(colored(\"Test prediction shape of 1 batch:\",\"blue\"),z_predict[0].shape)\n",
    "\n",
    "print(colored(\"Decoder:\",\"red\"))\n",
    "decoder_input = Input(shape=(latent_dim,), name=\"z_input\")\n",
    "\n",
    "# 2) Project & reshape to small feature map\n",
    "x = layers.Dense(8 * 8 * 128, activation=\"relu\")(decoder_input)\n",
    "x = layers.Reshape((8, 8, 128))(x)\n",
    "\n",
    "# 3) Upsampling blocks via transposed conv\n",
    "#    Each doubles H/W and halves channels (approximately)\n",
    "x = layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(64,  kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32,  kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    # 4) Final layer: restore to 3 channels\n",
    "decoder_output = layers.Conv2DTranspose(\n",
    "        3, kernel_size=3, strides=1, padding=\"same\", activation=\"sigmoid\", name=\"decoder_output\")(x)\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output, name=\"conv_decoder\")\n",
    "eps = tf.random.normal(shape=(64, latent_dim))  # 64 to batch size\n",
    "predict = decoder.predict(z_predict[0] + eps*tf.math.exp(z_predict[1]/2.))  # z_mean + z_log_var\n",
    "print(colored(\"Test prediction shape of 1 batch:\",\"blue\"),predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "506c2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder,beta=500, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return z_mean,z_log_var,reconstructed\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, reconstructed = self(data)\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstructed,axis=(1,2,3))\n",
    "            )\n",
    "            total_loss = kl_loss + self.beta * reconstruction_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\"loss\":total_loss,\"kl_loss\": kl_loss, \"reconstruction_loss\": self.beta *reconstruction_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdc40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 36s 2s/step - loss: 340.2839 - kl_loss: 0.0759 - reconstruction_loss: 340.2080 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 311.6874 - kl_loss: 0.6852 - reconstruction_loss: 325.9212 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 8s 403ms/step - loss: 316.3962 - kl_loss: 0.6224 - reconstruction_loss: 314.9947 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 8s 404ms/step - loss: 301.0453 - kl_loss: 0.6377 - reconstruction_loss: 307.4167 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 8s 405ms/step - loss: 295.4902 - kl_loss: 0.7370 - reconstruction_loss: 298.1697 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 292.1161 - kl_loss: 1.0321 - reconstruction_loss: 292.0881 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 281.4360 - kl_loss: 1.2460 - reconstruction_loss: 283.3245 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 280.3593 - kl_loss: 1.1920 - reconstruction_loss: 281.7396 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 8s 433ms/step - loss: 269.1790 - kl_loss: 1.2619 - reconstruction_loss: 279.9228 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 9s 437ms/step - loss: 278.9437 - kl_loss: 1.3001 - reconstruction_loss: 277.1989 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x265152c6e30>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "history = vae.fit(train_ds, epochs=10, validation_data=val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd41a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_ds\u001b[49m)))\n\u001b[0;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m vae(example)[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m fig,axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "example = next(iter(train_ds))\n",
    "\n",
    "output = vae(example)[2][0]\n",
    "\n",
    "fig,axes = plt.subplots(1,2)\n",
    "pil_img = tf.keras.preprocessing.image.array_to_img(example[0].numpy())\n",
    "axes[0].imshow(pil_img)\n",
    "pil_img = tf.keras.preprocessing.image.array_to_img(output.numpy())\n",
    "axes[1].imshow(pil_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
